---
title: "Recerca i Avaluació de models de predicció per estimar el 
 Carboni Aeri Total a partir de dades LIDAR a Andorra"
author: "Jordi ORDOÑEZ ADELLACH"
date: "5/30/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(randomForest)
library(reshape)
library(ggplot2)
op = function(x, d=2) sprintf(paste0("%1.",d,"f"), x) 


```

## 1. Dades per elaborar el model 

Disposem d'avaluacions de Carboni Aeri Total (CAT) sobre 194 parceles repartides 
pel territori nacional Andorrà. Aquestes parceles són circulars, de radis 
variables i s'ha procedit a la mesura física dels elements vegetals que hi són 
presents. En funció de les dades alomètriques obtingudes i de característiques 
de les espècies estudiades, s'ha associat a cada parcela un valor CAT.

També disposem de dades LIDAR per cadascuna de les parceles citades 
anteriorment. Associem les dades en un fitxer .csv


```{r,cache=TRUE}
data <- read.csv("infaCAT.csv", header = TRUE, sep = ";", dec = ",")
data$Habitat <- as.factor(data$Habitat)
head(data)
```

Disposem de 194 observacions de 35 variables entre les cuals, la identificació
de la parcela, el CAT associat a la parcela, el Habitat associat a la parcela, 
que no prové de les dades LIDAR i 32 variables obtingudes a partir de les 
oservacions LIDAR.

## 2. Selecció de variables

Dins de les variables per entrenar el model, no ens servirà la identificació de 
la parcela, ni tampoc ens seran d'utilitat variables que tinguin una 
variabilitat propera a 0 o variables fortament correlacionades amb altres.

Procedirem a identificar i filtrar les variables amb variabilitat propera a 0 
i després buscarem i eliminarem variables exoplicatives correlacionades amb un
coeficient de correlaciñó superior a 0,9 respecte a altres, excloient l'habitat 
d'aquest procediment per ser una variable no numérica.

```{r warning=FALSE,cache=TRUE}
# Near Zero Variable variables identifying and excluding
nzv <- nearZeroVar(data, saveMetrics = TRUE)
filtereddata <- data[, !nzv$nzv]
## Highly correlated variables identifying and excluding
numericdata <- filtereddata[, -c(1, 3, 4)]
dataCor <- cor(numericdata)
highlyCordata <- findCorrelation(dataCor, cutoff = .9)
filteredata2 <- numericdata[, -highlyCordata]
```

```{r echo=FALSE, fig.cap="CAT vs Variables", fig.height=8, fig.width=12, warning=FALSE,cache=TRUE}
outdata <- data$CAT
theme1 <- trellis.par.get()
theme1$plot.symbol$col <- rgb(.2, .2, .2, .4)
theme1$plot.symbol$pch <- 16
theme1$plot.line$col <- rgb(1, 0, 0, .7)
theme1$plot.line$lwd <- 2
trellis.par.set(theme1)
featurePlot(
  x = filteredata2,
  y = outdata,
  plot = "scatter",
  type = c("p", "smooth"),
  span = .5,
  layout = c(4, 5)
)
```

S'observa com la variable CAT té dependencia respecte a les variables 
seleccionades.

## 3. Entrenament del model

Seleccionarem un Training set a partir del 70% del total de les dades i deixarem 
el 30% de les dades restants en el Test set que només utilitzarem després 
d'haver seleccionat hiperàrametres i entrenat el model amb aquests 
hiperparametres, per avaluar el nostre model.


```{r warning=FALSE,cache=TRUE}
set.seed(3456)
data2 <- cbind(CAT = data$CAT, filteredata2, Habitat = data$Habitat)
trainIndex <- createDataPartition(data2$CAT,
  p = .7,
  list = FALSE,
  times = 1
)

Train <- data2[trainIndex, ]
Test <- data2[-trainIndex, ]
```

Per escollir els hiperparametres ntree (nombre d'arbres del model) i mtry (
nombre de variables que escollirem a l'atzar per efectuar cada divisió dins dels 
arbres), procedirem per CrossValidation sobre 6 blocs sobre el nostre Training 
set.

```{r echo=FALSE, fig.cap="rmse oob and test", fig.height=8, fig.width=12, warning=FALSE,cache=TRUE}
cvblocsid <- as.data.frame(split(sample(138), rep_len(1:6, 138)))

trainrf <- function(mtry, mintree, ntree) {
  ntrees <- seq(mintree, ntree, 20)
  mseoob <- matrix(data = NA, nrow = 6, ncol = length(ntrees))
  msetest <- matrix(data = NA, nrow = 6, ncol = length(ntrees))
  colnames(mseoob) <- ntrees
  colnames(msetest) <- ntrees
  for (i in 1:6) {
    train <- Train[-cvblocsid[, i], ]
    test <- Train[cvblocsid[, i], ]
    data.rf <- randomForest(train[, -c(1)], train[, c(1)],
      xtest = test[, -c(1)], test[, c(1)],
      importance = TRUE, ntree = ntree, mtry = mtry,
      proximity = FALSE
    )
    mseoob[i, ] <- (data.rf$mse[ntrees])
    msetest[i, ] <- (data.rf$test$mse[ntrees])
  }
  dmseoob <- (as.data.frame(lapply(data.frame(mseoob), mean)))
  dmsetest <- (as.data.frame(lapply(data.frame(msetest), mean)))
  df <- data.frame(
    trees = ntrees,
    rmseoob = unlist(dmseoob),
    rmsetest = unlist(dmsetest),
    mtry = as.factor(mtry)
  )
  df <- melt(df, id.vars = c("trees", "mtry"))
}

plottrainrf <- function(mtrys, mintree, ntrees) {
  error <- NULL
  for (mtry in mtrys) {
    error <- rbind(error, trainrf(mtry, mintree, ntrees))
  }
  error$value <- error$value^0.5
  g <- ggplot(error, aes(x = trees, y = value, colour = mtry)) +
    geom_line() +
    facet_wrap(~variable)
  print(g)
}

plottrainrf(mtrys = c(3, 8, 13, 18), 10, 5000)
```

Podem observar per diferents valors de *mtry* les mitjanes dels rmse obtinguts 
amb els 6 crossvalidation sobre els out-of-bag elements i sobre els tests 
respecte a cada selecció de blocs. Veiem una bona estabilització dels errors 
amb una utilització dels 2500 arbres, pel que centrarem la recerca del mtry 
optim repertint el test anterior sobre valors de mtry propers a 3.

```{r echo=FALSE, fig.cap="rmse oob and test", fig.height=8, fig.width=12, warning=FALSE,cache=TRUE}
plottrainrf(mtrys = c(1, 2, 3, 4, 5), 1000, 2500)
```

Observem un rmse òptim sobre tests estabilitzat amb 2500 abres i mtry=2 
variables i procedim a entrenar un model amb aquests paràmetres sense intervenir
en la llargada dels arbres ni en el nombre mínim d'elements per node. Aquests 
paràmetres es podrien optimitzar seguint el mateix procediment que hem utilitzat 
per mtry i ntree òptim, però no esperem una millora substàncial, però deixem la 
porta oberta.

```{r include=FALSE,cache=TRUE,fig.cap="IMportància dels predictors"}
data.rf <- randomForest(CAT ~ .,
  data = Train,
  importance = TRUE, ntree = 2500, mtry = 2,
  proximity = FALSE
)
importance <- data.rf$importance[order(data.rf$importance[, 1]), ]
df <- data.frame(
  names = factor(row.names(importance), levels = row.names(importance)),
  pMSE = importance[, 1]
)

plt <- ggplot(df) +
  geom_col(aes(pMSE, names), fill = "BLUE", width = 0.6)

plt
```




```{r include=FALSE,cache=TRUE}
real <- Test$CAT
predicted <- predict(data.rf, Test[, -1])
df <- data.frame(
  real = real,
  predicted = predicted
)

rmse <- (sum((df$real - df$predicted)^2) / length(df$real))^0.5
rrmse <- rmse / mean(Test$CAT)
```

Obtenim un rmse de `r op(rmse,2)` sobre el Test set i un rrmse de `r op(rrmse,2)`

```{r echo=FALSE, fig.cap="Predicted vs Real",cache=TRUE}
f <- function(x) x
g <- ggplot(df, aes(x = real, y = predicted)) +
  geom_point(shape = 1, size = 2, alpha = 0.5, color = "black", stroke = 2)+
  geom_function(fun = f) +
  xlim(0, 150) +
  ylim(0, 150)
print(g)
```

Observem l'adequació de les prediccions respecte a les dades reals

```{r echo=FALSE, fig.cap="% error predit sobre real",cache=TRUE}
perrorp <- (predicted - real) / real * 100
df <- data.frame(
  real = real,
  perrorp = perrorp
)
g <- ggplot(df, aes(x = real, y = perrorp)) +
  geom_point(shape = 1, size = 2, alpha = 0.5, color = "black", stroke = 2)+
  xlim(0, 150) +
  ylim(-150, 150)
print(g)
```

I finalment observem que els percentatges d'error són molt elelevats per valors
baixos de CAT reals, pel que en la predicció de CAT amb aquest model sobre la 
resta del territori, els valors baixos mereixerien una atenció suplementària a 
determinar.

Valor total del CAT sobre el Test Set : `r op(sum(real),0)` valor total predit 
sobre les mateixes parceles del test set : `r op(sum(predicted),0)` desviació de 
`r op(sum(predicted)/sum(real),2)`%.



## 4. Aplicació del model

A l'espera de les dades LIDAR sobre la resta del territori.
